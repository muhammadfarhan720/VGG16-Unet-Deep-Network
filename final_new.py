# -*- coding: utf-8 -*-
"""final_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xMRHd7NkjRfxUx3ZFpiHchqNFf4ac39d
"""

import numpy as np
import pandas as pd
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Model
import xgboost as xgb

x_val, y_val = np.load('DataPreprocessing/x_train.npy'), np.load('DataPreprocessing/y_train.npy')

X_train = x_val[:105,:,:,:]
y_train = y_val[:105,:,:]

# Use customary x_train and y_train variables
x_train = x_val[:105,:,:,:] #100 is best
y_train = y_val[:105,:,:]
y_train = np.expand_dims(y_train, axis=3)

# Load VGG16 model without classifier/fully connected layers
VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))

# Make loaded layers as non-trainable
for layer in VGG_model.layers:
    layer.trainable = False

# New model with only first 2 conv layers
new_model = Model(inputs=VGG_model.input, outputs=VGG_model.get_layer('block1_conv2').output)


X = x_train
X = X.reshape(-1, X.shape[3])

Y = y_train.reshape(-1)

dataset = pd.DataFrame(X)
dataset['Label'] = Y

X_for_training = dataset.drop(labels=['Label'], axis=1).values
Y_for_training = dataset['Label'].values

print("________________", "\n")
print("DONE WITH VGG")
print("________________", "\n")


model = xgb.XGBClassifier(tree_method='gpu_hist')
model.fit(X_for_training, Y_for_training)

#Save model for future use
import pickle
filename = 'model28'
pickle.dump(model, open(filename, 'wb'))
# 115334_sat.jpg
# 99913_sat.jpg
# 999764_sat.jpg

##########################################################
import cv2
import numpy as np
from keras.metrics import MeanIoU
import pickle
filename = 'model28'

loaded_model = pickle.load(open(filename, 'rb'))

folder = "train/"
file = "999764_sat.jpg"

test_img_path = folder + file

test_img = cv2.imread(test_img_path)
test_mask_path = folder + file.replace("_sat.jpg", "_mask.png")
test_mask = cv2.imread(test_mask_path, cv2.IMREAD_GRAYSCALE)  # Assuming mask is a grayscale image

test_img = cv2.resize(test_img, (256, 256), interpolation=cv2.INTER_NEAREST)
test_mask = cv2.resize(test_mask, (256, 256), interpolation=cv2.INTER_NEAREST)
test_img = test_img / 255.0
test_img = np.expand_dims(test_img, axis=0)

X_test_feature = new_model.predict(test_img)
X_test_feature = X_test_feature.reshape(-1, X_test_feature.shape[3])
prediction = loaded_model.predict(X_test_feature)
prediction_image = prediction.reshape((256, 256))


# Threshold the test mask
test_mask = np.where(test_mask > 127, 1, 0)

def iou(y_true, y_pred, num_classes=2):
    intersection = np.zeros(num_classes)
    union = np.zeros(num_classes)

    for cls in range(num_classes):
        intersection[cls] = np.sum((y_true == cls) & (y_pred == cls))
        union[cls] = np.sum((y_true == cls) | (y_pred == cls))

    return intersection / union

iou_result = iou(test_mask, prediction_image)

print("IoU for class 0:", iou_result[0])
print("IoU for class 1:", iou_result[1])

#############################################################

import matplotlib.pyplot as plt

test_img = test_img[0,:,:,:]

# Plot the original image, ground truth mask, predicted mask, and IoU
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(test_img)
axes[0].set_title('Original Image')
axes[0].axis('off')

axes[1].imshow(test_mask, cmap='gray')
axes[1].set_title('Ground Truth Mask')
axes[1].axis('off')

axes[2].imshow(prediction_image, cmap='gray')
axes[2].set_title(f'Predicted Mask (Class 1) White (IoU: {iou_result[1]:.2f})')
axes[2].axis('off')

plt.show()



